{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081794b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install htmldate\n",
    "# !pip install twython\n",
    "# !pip3 install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8f47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ameyagidh/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from htmldate import find_date\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium==4.0.0\n",
    "\n",
    "import selenium\n",
    "\n",
    "print(\"Selenium Version:\", selenium.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca85f7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.11.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (2.0.4)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/ameyagidh/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/ameyagidh/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /Users/ameyagidh/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "zsh:1: command not found: apt-get\n",
      "The operation couldnâ€™t be completed. Unable to locate a Java Runtime that supports apt.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "cp: /usr/lib/chromium-browser/chromedriver: No such file or directory\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'chrome_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--no-sandbox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--disable-dev-shm-usage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchromedriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mchrome_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchrome_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'chrome_options'"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!apt-get update \n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "\n",
    "from selenium import webdriver\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd5f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# driver = webdriver.Chrome( options=chrome_options)\n",
    "\n",
    "# # driver.quit()\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time  # Don't forget to import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e313bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newslinks(company, page_number):\n",
    "    \"\"\"For a given URL, scroll to relevant section to load appropriate HTML into driver,\n",
    "    iterate through all articles on page and append article URLs to a list\n",
    "\n",
    "    :param company: name of company to scrape articles for\n",
    "    :param page_number: page number on news website to iterate over \n",
    "\n",
    "    :return: list of articles URLs\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://www.investing.com/equities/{company}-news/{page_number}\"\n",
    "#     url = f\"https://uk.investing.com/equities/{company}-news/{page_number}\"\n",
    "    driver.get(url)\n",
    "\n",
    "    href = []\n",
    "\n",
    "    # scroll all the way to the bottom \n",
    "\n",
    "    old_position = 0\n",
    "    new_position = None\n",
    "\n",
    "    while new_position != old_position:\n",
    "        # Get old scroll position\n",
    "        old_position = driver.execute_script(\n",
    "                (\"return (window.pageYOffset !== undefined) ?\"\n",
    "                \" window.pageYOffset : (document.documentElement ||\"\n",
    "                \" document.body.parentNode || document.body);\"))\n",
    "        # Sleep and Scroll\n",
    "        time.sleep(1)\n",
    "        driver.execute_script((\n",
    "                \"var scrollingElement = (document.scrollingElement ||\"\n",
    "                \" document.body);scrollingElement.scrollTop =\"\n",
    "                \" scrollingElement.scrollHeight;\"))\n",
    "        # Get new position\n",
    "        new_position = driver.execute_script(\n",
    "                (\"return (window.pageYOffset !== undefined) ?\"\n",
    "                \" window.pageYOffset : (document.documentElement ||\"\n",
    "                \" document.body.parentNode || document.body);\"))\n",
    "        \n",
    "    cleaned_links = []\n",
    "    \n",
    "    # Iterate through all the articles on the page\n",
    "    for article_number in range(1,11): \n",
    "        article = driver.find_element_by_xpath(f'/html/body/div[5]/section/div[8]/article[{article_number}]')\n",
    "        article_html = article.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(article_html, \"lxml\")\n",
    "        for link in soup.find_all('a'): \n",
    "            # Get the href\n",
    "            partial_link = link.get('href')\n",
    "            if 'https' in partial_link: \n",
    "                cleaned_links.append(partial_link)\n",
    "            # Some links are 'internal' to the page and don't have https in them. The web page must be appended to these links\n",
    "            elif partial_link[0] == '/': \n",
    "                cleaned_links.append('https://uk.investing.com/'+partial_link) \n",
    "\n",
    "    return np.unique(cleaned_links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b181508",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'find_element_by_xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m all_company_urls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m119\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mget_newslinks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mastrazeneca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     all_company_urls\u001b[38;5;241m.\u001b[39mextend(results)\n\u001b[1;32m      7\u001b[0m all_company_urls\n",
      "Cell \u001b[0;32mIn [5], line 44\u001b[0m, in \u001b[0;36mget_newslinks\u001b[0;34m(company, page_number)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Iterate through all the articles on the page\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m11\u001b[39m): \n\u001b[0;32m---> 44\u001b[0m     article \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element_by_xpath\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[5]/section/div[8]/article[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marticle_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m     article_html \u001b[38;5;241m=\u001b[39m article\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minnerHTML\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(article_html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'find_element_by_xpath'"
     ]
    }
   ],
   "source": [
    "# Create empty list to append URLs \n",
    "\n",
    "all_company_urls = []\n",
    "for page in range(1,119):\n",
    "    results = get_newslinks('astrazeneca', page)\n",
    "    all_company_urls.extend(results)\n",
    "all_company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame \n",
    "\n",
    "article_sentiments.to_pickle(\"datascrapper.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0aea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentiments.to_csv(\"azn_article_sentiments_20210105.csv\", sep=',', encoding='utf-8', header=True)\n",
    "# Save URLS to text file\n",
    "\n",
    "with open('azn_urls_20210105.txt', 'w') as f:\n",
    "    for link in all_company_urls:\n",
    "        f.write(\"%s\\n\" % link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1ac97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
